This is the example to show how the trained model can be loaded into js.
If you want to see intersting things happen, look into the developer console.
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.0.0/dist/tf.min.js"></script>

<script type="module">


const MODEL_URL = "https://flori-boy.github.io/Hosting_Test/tensorflowjs_model_small/model.json";
const VOCAB_URL = "https://flori-boy.github.io/Hosting_Test/vocab.json"
const MAX_LEN = 195

async function getTokenisedWord(seedWord) {
    // get the JSON from URL
    return fetch(VOCAB_URL)
    .then(function(resp){
        return resp.json();
    })
    .then(function(data){
        console.log(data)
        console.log(seedWord)
        // tensor to return later
        var to_return = new Array(MAX_LEN).fill(0);
        var length = seedWord.length;
        // If the word is in our dictionary we assign it it's value
        // else it gets "deleted" by the offset
        var offset = 0;
        for(var i = 0; i < length; i++){
            if(data.hasOwnProperty(seedWord[i])){
                to_return[i-offset] = data[seedWord[i]]
            }
            else{
                offset = offset +1;
            }
        }
        console.log(to_return)
        const shape = [1, 195]
        return tf.tensor(to_return, shape)
    });
    }

// this is testing the model
async function get_model(){
    // calling the model
    const model = await tf.loadLayersModel(MODEL_URL);
    // test string
    var str = "How are you stop doing?"
    // tokenization
    var input = str.split(" ");
    // turning into tensor
    const tokens = await getTokenisedWord(input)
    tokens.print()
    // prediction
    const result = model.predict(tokens);
    // result
    result.print()
}
get_model()

</script>